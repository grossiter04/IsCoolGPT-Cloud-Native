# ğŸ“ IsCoolGPT - Assistente Educacional com IA

![Python](https://img.shields.io/badge/Python-3.11-blue?style=for-the-badge&logo=python&logoColor=white)
![FastAPI](https://img.shields.io/badge/FastAPI-0.104.0-009688?style=for-the-badge&logo=fastapi&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-Enabled-2496ED?style=for-the-badge&logo=docker&logoColor=white)
![Render](https://img.shields.io/badge/Deploy-Render-black?style=for-the-badge&logo=render&logoColor=white)

![CI Status](https://github.com/grossiter04/Atividade-Tinoco/actions/workflows/ci-pr-validation.yml/badge.svg)
![Staging Deploy](https://github.com/grossiter04/Atividade-Tinoco/actions/workflows/cd-staging.yml/badge.svg)
![Production Deploy](https://github.com/grossiter04/Atividade-Tinoco/actions/workflows/cd-prod.yml/badge.svg)

## ğŸ“– Sobre o Projeto

O **IsCoolGPT** Ã© uma aplicaÃ§Ã£o web Fullstack projetada para auxiliar estudantes a entenderem conceitos complexos de forma didÃ¡tica. Utilizando a API do **Google Gemini** (IA Generativa), o sistema recebe perguntas em linguagem natural e devolve explicaÃ§Ãµes simplificadas.

Este projeto foi desenvolvido com foco em **DevOps e Engenharia de Software Moderna**, implementando uma esteira completa de CI/CD automatizada.

---

## ğŸš€ Arquitetura e Tecnologias

A aplicaÃ§Ã£o segue uma arquitetura **Stateless** e conteinerizada, garantindo escalabilidade e consistÃªncia entre ambientes.

* **Backend:** Python 3.11 + FastAPI (Alta performance e assÃ­ncrono).
* **Frontend:** HTML5/CSS3/JS (Servido estaticamente pelo FastAPI).
* **IA Engine:** Google Gemini 2.5 Flash.
* **ContainerizaÃ§Ã£o:** Docker (Multi-stage builds para seguranÃ§a e otimizaÃ§Ã£o).
* **CI/CD:** GitHub Actions.
* **Infraestrutura:** Render (Hospedagem de Containers).

### ğŸ“‚ Estrutura de Pastas

```text
Atividade-Tinoco/
â”œâ”€â”€ .github/workflows/    # Pipelines de AutomaÃ§Ã£o (CI/CD)
â”œâ”€â”€ static/               # Frontend (Interface do UsuÃ¡rio)
â”œâ”€â”€ tests/                # Testes Automatizados (Pytest)
â”œâ”€â”€ main.py               # AplicaÃ§Ã£o Principal (API + Rotas)
â”œâ”€â”€ Dockerfile            # Receita da Imagem Docker
â”œâ”€â”€ docker-compose.yml    # OrquestraÃ§Ã£o para desenvolvimento local
â”œâ”€â”€ requirements.txt      # DependÃªncias do Projeto
â””â”€â”€ README.md             # DocumentaÃ§Ã£o
```

---

## âš™ï¸ Pipeline de CI/CD

O projeto utiliza uma estratÃ©gia de versionamento baseada em 3 branches principais (`develop`, `staging`, `main`), com automaÃ§Ã£o total via GitHub Actions:

1.  **IntegraÃ§Ã£o ContÃ­nua (CI):**
    * A cada *Push* ou *Pull Request*, o sistema roda linting (`flake8`), testes unitÃ¡rios (`pytest`) e verifica se o Dockerfile Ã© vÃ¡lido.
2.  **Deploy em Staging (CD):**
    * Ao aprovar cÃ³digo na branch `staging`, o deploy Ã© feito automaticamente no ambiente de testes.
3.  **PromoÃ§Ã£o AutomÃ¡tica:**
    * Se o deploy em Staging for bem-sucedido, um bot realiza o *merge* automÃ¡tico para a branch `main`.
4.  **Deploy em ProduÃ§Ã£o (CD):**
    * A atualizaÃ§Ã£o da `main` dispara o deploy no ambiente de produÃ§Ã£o final.

---

## ğŸ› ï¸ Como Rodar Localmente

### PrÃ©-requisitos
* Docker instalado (com Docker Compose)
* Uma chave de API do Google Gemini (`GEMINI_API_KEY`)

### Passo 1: ConfiguraÃ§Ã£o Inicial
1.  Clone o repositÃ³rio:
    ```bash
    git clone [https://github.com/grossiter04/IsCoolGPT-Cloud-Native.git](https://github.com/grossiter04/IsCoolGPT-Cloud-Native.git)
    cd IsCoolGPT-Cloud-Native
    ```

2.  Crie o arquivo `.env` na raiz do projeto e adicione sua chave:
    ```text
    GEMINI_API_KEY=cole_sua_chave_aqui
    ```

### Passo 2: Rodando com Docker (Recomendado)

VocÃª tem duas opÃ§Ãµes para rodar o container:

#### ğŸŸ¢ OpÃ§Ã£o A: Usando Docker Compose (Mais FÃ¡cil)
Como o projeto jÃ¡ possui o arquivo `docker-compose.yml`, basta um comando para subir tudo:

```bash
docker compose up --build
```
*O site estarÃ¡ disponÃ­vel em: `http://localhost:8000`*

#### ğŸŸ  OpÃ§Ã£o B: Usando Docker Puro
Se preferir rodar manualmente sem o compose:

1.  Construa a imagem:
    ```bash
    docker build -t iscoolgpt .
    ```
2.  Rode o container ligando a porta 8000 e passando o arquivo .env:
    ```bash
    docker run -p 8000:8000 --env-file .env iscoolgpt
    ```

### Passo 3: Rodando sem Docker (Python Puro)
Caso nÃ£o queira usar Docker:

1.  Crie um ambiente virtual e instale as dependÃªncias:
    ```bash
    python -m venv venv
    source venv/bin/activate  # No Windows: venv\Scripts\activate
    pip install -r requirements.txt
    ```
2.  Inicie o servidor:
    ```bash
    uvicorn main:app --reload
    ```

---

## ğŸ§ª Rodando os Testes

Para garantir a qualidade do cÃ³digo, execute os testes automatizados.
**Importante:** VocÃª deve estar com o ambiente virtual (`venv`) ativado para que o pytest encontre as dependÃªncias.

1.  **Ative o ambiente virtual** (se ainda nÃ£o estiver):
    ```bash
    # Linux/Mac
    source venv/bin/activate

    # Windows
    venv\Scripts\activate
    ```

2.  **Execute os comandos:**
    ```bash
    # Roda todos os testes
    pytest
    ```

> **Nota:** Os testes de API utilizam *Mocks* para simular o Google Gemini, garantindo que vocÃª nÃ£o gaste crÃ©ditos da sua API durante o desenvolvimento.

---

## ğŸ”— Links do Projeto (Deploy)

* **Ambiente de ProduÃ§Ã£o:** [Acessar IsCoolGPT (Prod)](https://atividade-tinoco.onrender.com)
* **Ambiente de Staging:** [Acessar IsCoolGPT (Staging)](https://atividade-tinoco-1.onrender.com)
* **DocumentaÃ§Ã£o da API (Swagger):** [Ver Docs](https://atividade-tinoco-1.onrender.com/docs)

---

## ğŸ‘¨â€ğŸ’» Autor

**Gabriel Rossiter**
* Projeto desenvolvido para a disciplina de Cloud Computing.